{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8412680e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.170-py3-none-any.whl (834 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.2/834.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: requests in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.9/336.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.7-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-macosx_11_0_arm64.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tommycalvy/anaconda3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Installing collected packages: typing-inspect, tenacity, pydantic, multidict, marshmallow, frozenlist, async-timeout, yarl, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.170 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 tenacity-8.2.2 typing-inspect-0.8.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0332ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_INSTRUCTOR_XL = \"hkunlp/instructor-xl\"\n",
    "LLM_FASTCHAT_T5_XL = \"lmsys/fastchat-t5-3b-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0b5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommycalvy/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a754305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepoQA:\n",
    "    question_check_template = \"\"\"Given the following pieces of context, determine if the question is able to be answered by the information in the context.\n",
    "Respond with 'yes' or 'no'.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "    QUESTION_CHECK_PROMPT = PromptTemplate(\n",
    "        template=question_check_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    def __init__(self, config: dict={}):\n",
    "        self.config = config\n",
    "        self.embedding = None\n",
    "        self.vectordb = None\n",
    "        self.llm = None\n",
    "        self.qa = None\n",
    "    \n",
    "    # The following class methods are useful to create global GPU model instances\n",
    "    # This way we don't need to reload models in an interactive app,\n",
    "    # and the same model instance can be used across multiple user sessions\n",
    "    @classmethod\n",
    "    def create_instructor_xl(cls):\n",
    "        return HuggingFaceInstructEmbeddings(model_name=EMB_INSTRUCTOR_XL, model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "    @classmethod\n",
    "    def create_fastchat_t5_xl(cls, load_in_8bit=False):\n",
    "        return pipeline(\n",
    "            task=\"text2text-generation\",\n",
    "            model = LLM_FASTCHAT_T5_XL,\n",
    "            model_kwargs={\"device_map\": \"auto\", \"load_in_8bit\": load_in_8bit, \"max_length\": 512, \"temperature\": 0.}\n",
    "        )\n",
    "    \n",
    "    def init_models(self) -> None:\n",
    "        load_in_8bit = self.config[\"load_in_8bit\"]\n",
    "\n",
    "        if self.config[\"embedding\"] == EMB_INSTRUCTOR_XL:\n",
    "            if self.embedding is None:\n",
    "                self.embedding = RepoQA.create_instructor_xl()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid config\")\n",
    "        \n",
    "        if self.config[\"llm\"] == LLM_FASTCHAT_T5_XL:\n",
    "            if self.llm is None:\n",
    "                self.llm = RepoQA.create_fastchat_t5_xl(load_in_8bit=load_in_8bit)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid config\")\n",
    "    \n",
    "    def vectorize_repo(repo_path: str):\n",
    "        print(repo_path)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            # Set a really small chunk size, just to show.\n",
    "            chunk_size = 100,\n",
    "            chunk_overlap  = 20,\n",
    "            length_function = len,\n",
    "        )\n",
    "        for root, dir_names, file_names in os.walk(repo_path):\n",
    "            for f in file_names:\n",
    "                fname = os.path.join(root, f)\n",
    "                if f.endswith() == 'post.go':\n",
    "                    with open(fname) as myfile:\n",
    "                        doco = myfile.read()\n",
    "                    texts = text_splitter.create_documents([doco])\n",
    "                    for text in texts:\n",
    "                        print(text)\n",
    "\n",
    "\n",
    "    def get_answer(self, question: str) -> str:\n",
    "        hf_llm = HuggingFacePipeline(pipeline=self.llm)\n",
    "        self.qa = RetrievalQA.from_chain_type(llm=hf_llm, chain_type=\"stuff\", retriever=self.vectordb.as_retriever(search_kwargs={\"k\":4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b653815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tommycalvy/aws/gatekeeper/crud_service\n",
      "The directory name is: ['protos', 'post', 'user', 'service']\n",
      "The directory name is: []\n",
      "The directory name is: []\n",
      "132\n",
      "The directory name is: []\n",
      "The directory name is: []\n"
     ]
    }
   ],
   "source": [
    "RepoQA.vectorize_repo(\"/Users/tommycalvy/aws/gatekeeper/crud_service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137652f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
